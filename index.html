<!DOCTYPE HTML>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <title>Tianhai Liang</title>

    <meta name="author" content="Tianhai Liang">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="shortcut icon" href="images/favicon/favicon.png" type="image/x-icon">
    <link rel="stylesheet" type="text/css" href="stylesheet.css">
    
  </head>

  <body>
    <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr style="padding:0px">
              <td style="padding:2.5%;width:63%;vertical-align:middle">
                <p class="name" style="text-align: center;">
                  Tianhai Liang | Ê¢ÅÂ§©Êµ∑
                </p>
                <p>
                  I am Tianhai Liang, a Master student in <em>Artificial Intelligence & Robotics</em> at <a href="https://iiis.tsinghua.edu.cn/">Institute for Interdisciplinary Information Sciences (IIIS), Tsinghua University</a> under the supervision of <a href="http://hxu.rocks/"> Prof. Huazhe Xu</a>.
                </p>
                <p>
                  I obtained a Bachelor's degree in <em>Automation</em> from <a href="https://www.hitsz.edu.cn/">Harbin Institute of Technology, Shenzhen</a>, and a minor Bachelor's degree in <em>Computer Science</em> as an outstanding graduate. Both my graduation projects in the Automation major and the Computer Science minor received Best Bachelor Thesis Awards, making me <strong>the first person in HIT's history to receive dual Best Bachelor Thesis Awards</strong>. During my undergraduate study, I am fortunate to be mentored by <a href="https://www.nrs-lab.com/people-2/">Prof. Haoyao Chen</a> and <a href="https://faculty.hitsz.edu.cn/chenyongyong">Prof. Yongyong Chen</a>. 
                </p>
                <p>
                  My research interests mainly include reinforcement learningüñ•Ô∏è, Computer hapticsüñêÔ∏è and roboticsü§ñ. I‚Äôm particularly interested in the integration of reinforcement learning algorithms with actual robotic hardwareü¶æ.
                </p>
                <p>
                  Apart from this, I am also particularly interested in medicineü©∫ and electronic circuitsüîå.
                </p>
                <p style="text-align:center">
                  <a href="tianhailiang.cn@gmail.com">Email</a> &nbsp;/&nbsp;
                  <a href="data/personal_cv.pdf">CV (expired in June 2023)</a> &nbsp;/&nbsp;
                  <a href="https://scholar.google.com/citations?user=CEWTgvkAAAAJ">Google Scholar</a> &nbsp;/&nbsp;
                  <!-- <a href="https://twitter.com/MalcomX920676">Twitter</a> &nbsp;/&nbsp; -->
                  <a href="https://github.com/Tinhal">Github</a>
                </p>
              </td>
              <td style="padding:2.5%;width:40%;max-width:40%">
                <a href="images/Me2.jpg"><img style="width:90%;max-width:90%;object-fit: cover" alt="profile photo" src="images/Me2.jpg" class="hoverZoomLink"></a>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
              <td style="padding-left:20px; padding-top:20px; width:100%;vertical-align:middle">
                <h2>Publications</h2>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

    <tr>
      <td style="padding:20px;width:25%;vertical-align:middle">
        <div class="one">
          <img src='images/demo_minigolf_480p.gif' width=100%>
        </div>
      </td>
      <td style="padding: 10px; width:75%; vertical-align:middle">
        <a class="a1" href="https://arxiv.org/abs/2410.14972">
          <span class="papertitle">MENTOR: Mixture-of-Experts Network with Task-Oriented Perturbation for Visual Reinforcement Learning</span>
        </a>
        <br>
          <a class="a2" href="https://suninghuang19.github.io/">Suning Huang*</a>,
          <span>Zheyu Zhang*</span>,
          <strong>Tianhai Liang</strong>,
          <span>Yihan Xu</span>,
          <span>Zhehao Kou</span>,
          <span>Chenhao Lu</span>,
          <span>Guowei Xu</span>,
          <a class="a2" href="https://steven-xzr.github.io/">Zhengrong Xue</a>,
          <a class="a2" href="http://hxu.rocks/index.html">Huazhe Xu</a>,
        <br>
        <i><strong>arXiv</strong></i>, 2024
        <br>
        <a href="https://suninghuang19.github.io/mentor_page/">project page</a>
        /
        <a href="https://arxiv.org/abs/2410.14972">arXiv</a>
        <p></p>
        <p>
          A leading model-free visual RL algorithm which achieves state-of-the-art performances in learning efficiency and performance on various tasks. We can even directly train it on the real robot!
        </p>
      </td>
    </tr>

    <tr>
      <td style="padding:20px;width:25%;vertical-align:middle">
        <div class="one">
          <img src='images/dcmm_video.gif' width=100%>
        </div>
      </td>
      <td style="padding: 10px; width:75%; vertical-align:middle">
        <a class="a1" href="https://arxiv.org/abs/2409.10319">
          <span class="papertitle">Catch It! Learning to Catch in Flight with Mobile Dexterous Hands</span>
        </a>
        <br>
          <a class="a2" href="https://hang0610.github.io/">Yuanhang Zhang*</a>,
          <strong>Tianhai Liang*</strong>,
          <a class="a2" href="https://chenzheny.github.io/">Zhenyang Chen</a>,
          <a class="a2" href="https://yanjieze.com/">Yanjie Ze</a>,
          <a class="a2" href="http://hxu.rocks/index.html">Huazhe Xu</a>,
        <br>
        <i><strong>arXiv</strong></i>, 2024
        <br>
        <a href="https://mobile-dex-catch.github.io/">project page</a>
        /
        <a href="https://arxiv.org/abs/2409.10319">arXiv</a>
        <p></p>
        <p>
          We build a mobile manipulator with a dexterous hand, and leverage reinforcement learning to train a whole-body control policy for the robot to catch diverse objects randomly thrown by humans.
        </p>
      </td>
    </tr>

    <tr>
      <td style="padding:20px;width:25%;vertical-align:middle">
        <div class="one">
          <img src='images/dcugl.png' width=100%>
        </div>
      </td>
      <td style="padding: 10px; width:75%; vertical-align:middle">
        <a class="a1" href="https://dl.acm.org/doi/10.1145/3664290">
          <span class="papertitle">Data Completion-guided Unified Graph Learning for Incomplete Multi-View Clustering</span>
        </a>
        <br>
        <strong>Tianhai Liang*</strong>,
          <span>Qiangqiang Shen*</span>,
          <span>Shuqin Wang</span>,
          <a class="a2" href="https://scholar.google.com/citations?user=ny2mn-cAAAAJ&hl=zh-CN">Yongyong Chen</a>,
          <span>Guokai Zhang</span>,
          <span>Junxin Chen</span>,
        <br>
        <i>ACM Transactions on Knowledge Discovery from Data (<strong>TKDD</strong>)</i>, 2024
        <br>
        <a href="https://dl.acm.org/doi/10.1145/3664290">paper</a>
        <p></p>
        <p>
          We propose one novel IMVC method named Data Completion-guided Unified Graph Learning (DCUGL), which could complete the data of missing views and fuse multiple learned view-specific similarity matrices into one unified graph.
        </p>
      </td>
    </tr>


    <tr>
      <td style="padding:20px;width:25%;vertical-align:middle">
        <div class="one">
          <img src='images/riemann.gif' width=100%>
        </div>
      </td>
      <td style="padding: 10px; width:75%; vertical-align:middle">
        <a class="a1" href="https://riemann-web.github.io/">
          <span class="papertitle">RiEMann: Near Real-Time SE(3)-Equivariant Robot Manipulation without Point Cloud Segmentation</span>
        </a>
        <br>
          <a class="a2" href="https://chongkaigao.com/">Chongkai Gao</a>,
          <a class="a2" href="https://steven-xzr.github.io/">Zhengrong Xue</a>,
          <span>Shuying Deng</span>,
          <strong>Tianhai Liang</strong>,
          <span>Siqi Yang</span>,
          <a class="a2" href="https://linsats.github.io/">Lin Shao</a>,
          <!-- <span>Mingrun Jiang</span>, -->
          <a class="a2" href="https://hxu.rocks/">Huazhe Xu</a>
        <br>
        <i>Conference on Robot Learning (<strong>CoRL</strong>)</i>, 2024
        <br>
        <a href="https://riemann-web.github.io/">project page</a>
        /
        <a href="https://arxiv.org/abs/2403.19460">arXiv</a>
        <p></p>
        <p>
          We present RiEMann, an end-to-end near Real-time SE(3)-Equivariant Robot Manipulation imitation learning framework from scene point cloud input. Compared to previous methods that rely on descriptor field matching, RiEMann directly predicts the target poses of objects for manipulation without any object segmentation.
        </p>
      </td>
    </tr>


    <tr>
      <td style="padding:20px;width:25%;vertical-align:middle">
        <div class="one">
          <img src='images/clothesnet.png' width=100%>
        </div>
      </td>
      <td style="padding: 10px; width:75%; vertical-align:middle">
        <a class="a1" href="https://sites.google.com/view/clothesnet/">
          <span class="papertitle">ClothesNet: An Information-Rich 3D Garment Model Repository with Simulated Clothes Environment</span>
        </a>
        <br>
        <span>Bingyang Zhou</span>,
        <span>Haoyu Zhou*</span>,
        <strong>Tianhai Liang*</strong>,
        <span>Qiaojun Yu</span>,
        <a class="a2" href="https://sihengz02.github.io/">Siheng Zhao</a>,
        <span>Yuwei Zeng</span>,
        <span>Jun Lv</span>,
        <span>Siyuan Luo</span>,
        <span>Qiancai Wang</span>,
        <span>Xinyuan Yu</span>,
        <span>Haonan Chen</span>,
        <a class="a2" href="https://www.mvig.org/">Cewu Lu</a>,
        <a class="a2" href="https://linsats.github.io/">Lin Shao</a>
        <br>
        <i>IEEE International Conference on Computer Vision (<strong>ICCV</strong>)</i>, 2023
        <br>
        <a href="https://sites.google.com/view/clothesnet/">project page</a>
        /
        <a href="https://arxiv.org/abs/2308.09987">arXiv</a>
        <p></p>
        <p>
          We present ClothesNet: a large-scale dataset of 3D clothes objects with information-rich annotations. Our dataset consists of around 4400 models covering 11 categories annotated with clothes features, boundary lines, and key points.
        </p>
      </td>
    </tr>



    <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
        <tr>
        <td style="padding-left:20px; padding-top:20px; width:100%;vertical-align:middle">
          <h2>Experience</h2>
        </td>
      </tr>
    </tbody></table>
    <table width="100%" align="center" border="0" cellpadding="10"><tbody>
      <tr>
        <td style="padding-left:30px;padding-right:20px;width:20%;vertical-align:middle"><img src="images/THU.png" ,="" width="80%"></td>
        <td width="80%" valign="center">
          <b>Tsinghua University</b>, China
          <br> 2024.07 - Present
          <br>
          <br> <b>Master Student in Computer Science</b>
          <br> Advisor: <a href="http://hxu.rocks/"> Prof. Huazhe Xu</a>
        </td>
      </tr>
      <tr>
        <td style="padding-left:40px;padding-right:20px;width:20%;vertical-align:middle"><img src="images/sqz.png" ,="" width="65%"></td>
        <td width="80%" valign="center">
          <b>Shanghai Qi Zhi Institute</b>, China
          <br> 2024.06 - Present
          <br>
          <br> <b>Intern</b>
        </td>
      </tr>
      <tr>
        <td style="padding-left:20px;padding-right:20px;width:20%;vertical-align:middle"><img src="images/HITsz.png" ,="" width="90%"></td>
        <td width="80%" valign="center">
          <b>Harbin Institute of Technology, Shenzhen</b>, China
          <br> 2020.09 - 2024.06
          <br>
          <br> <b>B.Eng. in Automation with a Minor in Computer Science</b>
        </td>
      </tr>

    </tbody></table>
    

    <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr>
      <td style="padding-left:20px; padding-top:20px; width:100%;vertical-align:middle">
        <h2>Selected Awards and Honors</h2>
      </td>
    </tr>
    </tbody></table>
    <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

      <tr><td style="padding-left:30px;width:100%;vertical-align:middle">
        <p></p>
        <li><strong>2024: Best Bachelor Thesis Award of HITsz in Automation</strong></li>
        <li><strong>2024: Best Bachelor Thesis Award of HITsz in Computer Science</strong></li>
        <li><strong>2024: Outstanding Graduates of HITsz</strong></li>
        <li><strong>2023: National Scholarship (Top 0.2% nationwide)</strong></li>
        <li>2023: First Class Academic Scholarship (top 5% in Harbin Institute of Technology, Shenzhen)</li>
        <li>2022: Top Ten Outstanding Studying Stars (10 out of all students in Harbin Institute of Technology)</li>
        <li>2022: First Class Academic Scholarship (top 5% in Harbin Institute of Technology, Shenzhen)</li>
        <li>2022: TOPBAND Outstanding Scholarship (top 1% in Harbin Institute of Technology, Shenzhen)</li>
        <li><strong>2021: National Scholarship (Top 0.2% nationwide)</strong></li>
        <li>2021: Outstanding student model</li>
        <li>2021: First Class Academic Scholarship (top 5% in Harbin Institute of Technology, Shenzhen)</li>
        <p></p>
        <li><strong>2022: National First Prize in RoboMaster University Championship (RMUC)</strong></li>
        <li><strong>2021: National Second Prize in National Undergraduate Electronics Design Contest (NUEDC)</strong></li>
        <li><strong>2021: National Third Prize in National Undergraduate Smart Car Contest</strong></li>
        <li>2022: Provincial First Prize in China Undergraduate Mathematical Contest in Modeling (CUMCM)</li>
        <li>2022: Provincial Second Prize in National Undergraduate Smart Car Contest</li>
        <li>2022: Honorable Mention in Mathematical Contest in Modeling (MCM)</li>
        <li>2021: Provincial Third Prize in China Undergraduate Mathematical Contest in Modeling (CUMCM)</li>
      </td>
    </tr>

    <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr>
      <td style="padding-left:20px; padding-top:20px; width:100%;vertical-align:middle">
        <h2>Academic Performance</h2>
      </td>
    </tr>
    </tbody></table>
    <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

      <tr><td style="padding-left:30px;width:100%;vertical-align:middle">
        <p></p>
        <li>GPA: 3.921/4.0</li>
        <li>Achieved A+ in more than 60 Courses.</li>
      </td>
    </tr>

    <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;padding-top: 30px; margin-right: auto;margin-left:auto;"><tbody>
      <tr>
      <td style="padding-left:20px; padding-top:20px; width:100%;vertical-align:middle">
        <h2>Personal Interests</h2>
      </td>
    </tr>
    </tbody></table>
    <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody></tbody>
    
      <tr><td style="padding-left:30px;width:100%;vertical-align:middle">
        <p>
          </p>
          <li><strong>Guitarüé∏:</strong> I love playing fingerstyle guitar. Music always makes me happy.</li>
          <li><strong>Hardware‚öôÔ∏è:</strong> I am an electronics enthusiast and I enjoy working on hardware projects in my spare time.</a></li>
          <li><strong>Medicineü´Ä:</strong> I like reading professional medical books, which is how I understand that the human body is a great mysterious structure.</a></li>
          <p>
          </p>
        </td>
      </tr>

          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
              <td style="padding:0px">
                <br>
                <div style="width: 25%;margin-left: auto;margin-right: auto;">
                  <script type="text/javascript" id="clustrmaps" src="//clustrmaps.com/map_v2.js?d=1F3P2a3OkmSetSpQcdOcSiuCDtwYhpiMJOSarLyeqi0&cl=ffffff&w=a"></script>
                </div>
                <p style="text-align:center;font-size:small;">
                  The source code is stolen from <a href="https://jonbarron.info/">Jon Barron</a>. What a concise tempelate!
                </p>
              </td>
            </tr>
          </tbody></table>
        </td>
      </tr>
    </table>
  </body>
</html>
